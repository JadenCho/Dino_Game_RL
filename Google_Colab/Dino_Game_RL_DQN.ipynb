{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PS62i8xNJuFQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91f0f3b0-1d32-42b4-fe8b-4b5cb9e4fa16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ]
        }
      ],
      "source": [
        "!pip install selenium > /dev/null\n",
        "!pip install stable_baselines3 > /dev/null\n",
        "!apt-get update > /dev/null # to update ubuntu to correctly run apt install\n",
        "!apt install chromium-chromedriver> /dev/null\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-QNEdtDy4VQC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "import gym\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "from gym import spaces\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "import base64\n",
        "import cv2\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import random\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "import math\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.ppo.policies import CnnPolicy as CnnPolicy_PPO\n",
        "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.callbacks import CheckpointCallback\n",
        "from stable_baselines3 import DQN\n",
        "from stable_baselines3.dqn.policies import CnnPolicy as CnnPolicy_DQN"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Driver and Environment"
      ],
      "metadata": {
        "id": "iaAALNxTlqTN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "cILGLW5R4YDZ"
      },
      "outputs": [],
      "source": [
        "class Game():\n",
        "\tdef __init__(self):\n",
        "\t\tself.chrome_options = webdriver.ChromeOptions()\n",
        "\t\tself.chrome_options.add_argument(\"--mute-audio\")\n",
        "\t\tself.chrome_options.add_argument(\"--headless\")\n",
        "\t\tself.chrome_options.add_argument('--no-sandbox')\n",
        "\t\tself.chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "\t\tself.chrome_options.add_argument('start-maximized')\n",
        "\t\tself.driver = webdriver.Chrome('chromedriver', options=self.chrome_options)\n",
        "\t\tself.driver.get('https://tuckercraig.com/dino/')\n",
        "\n",
        "\tdef Start(self):\n",
        "\t\t'''\n",
        "\t\tOpen the Game Instance in Chrome\n",
        "\t\t'''\n",
        "\t\tself.driver.get('https://tuckercraig.com/dino/')\n",
        "\n",
        "\tdef Action(self, action):\n",
        "\t\t'''\n",
        "\t\tPerform action\n",
        "\t\t'''\n",
        "\t\tself.driver.find_element(By.TAG_NAME, 'body').send_keys(action)\n",
        "\n",
        "\tdef Refresh(self):\n",
        "\t\t'''\n",
        "\t\tRefresh the Chrome Tab\n",
        "\t\t'''\n",
        "\t\tself.driver.refresh()\n",
        "\t\tWebDriverWait(self.driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"runner-canvas\")))\n",
        "\n",
        "\tdef Restart(self):\n",
        "\t\t'''\n",
        "\t\tRefresh the Chrome Tab and start the game again\n",
        "\t\t'''\n",
        "\t\tWebDriverWait(self.driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"runner-canvas\")))\n",
        "\t\tself.driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.SPACE)\n",
        "\n",
        "\tdef Get_Score(self):\n",
        "\t\t'''\n",
        "\t\tReturn the score of the gane\n",
        "\t\t'''\n",
        "\t\tscore = self.driver.execute_script(\"return Runner.instance_.distanceMeter.digits\")\n",
        "\t\tscore = ''.join(score)\n",
        "\n",
        "\t\treturn score\n",
        "\n",
        "\tdef Img_State(self):\n",
        "\t\t'''\n",
        "\t\tReturn the image of the current state\n",
        "\t\t'''\n",
        "\t\timg = self.driver.execute_script(\"return document.querySelector('canvas.runner-canvas').toDataURL()\")\n",
        "\t\treturn img\n",
        "\n",
        "\tdef Done_State(self):\n",
        "\t\t'''\n",
        "\t\tReturn whether the dino has crashed or not\n",
        "\t\t'''\n",
        "\t\tdone = self.driver.execute_script(\"return Runner.instance_.crashed\")\n",
        "\t\t\n",
        "\t\treturn done\n",
        "\n",
        "class DinoEnv(gym.Env):\n",
        "\tdef __init__(self, width=120, height=120):\n",
        "\t\tself.screen_width = width\n",
        "\t\tself.screen_height = height\n",
        "\n",
        "\t\tself.action_space = spaces.Discrete(3) # Do nothing, jump, crouch\n",
        "\t\tself.observation_space = spaces.Box(low=0, high=255, shape=(self.screen_width, self.screen_height, 4), dtype=np.uint8)\n",
        "\n",
        "\t\tself.state_queue = deque(maxlen=4)\n",
        "\n",
        "\t\tself.game = Game()\n",
        "\n",
        "\t\tself.action_list = [Keys.ARROW_LEFT, Keys.ARROW_UP, Keys.ARROW_DOWN]\n",
        "\t\taction_ = ActionChains(self.game.driver)\n",
        "\t\tself.key_press = [action_.key_down(act) for act in self.action_list]\n",
        "\t\tself.key_unpress = [action_.key_up(act) for act in self.action_list]\n",
        "\n",
        "\tdef Env_Start(self):\n",
        "\t\t'''\n",
        "\t\tStart the Dino Game Instance\n",
        "\t\t'''\n",
        "\t\tself.game.Start()\n",
        "\n",
        "\tdef step(self, action):\n",
        "\t\t'''\n",
        "\t\tReturns Observation, reward, done, other\n",
        "\t\t'''\n",
        "\t\tself.game.Action(self.action_list[action])\n",
        "\n",
        "\t\tnext_state = self.next_state()\n",
        "\n",
        "\t\tdone = self.done_state()\n",
        "\n",
        "\t\treward = 1 if not done else -100\n",
        "\n",
        "\t\tscore = self.game.Get_Score()\n",
        "\n",
        "\t\t#time.sleep(0.02)\n",
        "\n",
        "\t\treturn next_state, reward, done, {'score': score}\n",
        "\n",
        "\tdef reset(self):\n",
        "\t\t'''\n",
        "\t\tReset the Dino Game Instance\n",
        "\t\t'''\n",
        "\t\tself.game.Restart()\n",
        "\n",
        "\t\treturn self.next_state()\n",
        "\n",
        "\tdef get_state_img(self):\n",
        "\t\t'''\n",
        "\t\tReturns an image of the current state of the game\n",
        "\t\t'''\n",
        "\t\tLEADING_TEXT = \"data:image/png;base64,\"\n",
        "\t\timg = self.game.Img_State()\n",
        "\t\timg = img[len(LEADING_TEXT):]\n",
        "\n",
        "\t\treturn np.array(Image.open(BytesIO(base64.b64decode(img))))\n",
        "\n",
        "\tdef next_state(self):\n",
        "\t\t'''\n",
        "\t\tProcesses the image of the state\n",
        "\t\t'''\n",
        "\t\timg = cv2.cvtColor(self.get_state_img(), cv2.COLOR_BGR2GRAY)\n",
        "\t\timg = img[:, :480] # Cropping\n",
        "\t\timg = cv2.resize(img, (self.screen_width, self.screen_height)) # Resize\n",
        "\n",
        "\t\tself.state_queue.append(img)\n",
        "\n",
        "\t\tif len(self.state_queue) < 4:\n",
        "\t\t\treturn np.stack([img] * 4, axis=-1)\n",
        "\t\telse:\n",
        "\t\t\treturn np.stack(self.state_queue, axis=-1)\n",
        "\t\t#return img\n",
        "\n",
        "\tdef Score(self):\n",
        "\t\t'''\n",
        "\t\tObtain and return score from the Game Instance\n",
        "\t\t'''\n",
        "\t\tscore = self.game.Get_Score()\n",
        "\t\treturn score\n",
        "\n",
        "\tdef done_state(self):\n",
        "\t\t'''\n",
        "\t\tCheck and return whether the Dino has crashed or not\n",
        "\t\t'''\n",
        "\t\treturn self.game.Done_State()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d = DinoEnv()\n",
        "state = d.reset()\n",
        "img = []\n",
        "img.append(state)\n",
        "for i in range(15):\n",
        "\tnext_state, reward, done, _ = d.step(1)\n",
        "\timg.append(next_state)\n",
        "\tplt.figure(i)\n",
        "\tplt.imshow(img[i])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YGzS-qFvE1mM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DQN"
      ],
      "metadata": {
        "id": "bSNO0Sd7lbOY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BW8YdE04pGq",
        "outputId": "5f166a39-8b16-45de-bf5d-1f409d7b29ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "episode: 278/1000, score: 11, max score: 45, e: 0.0449, time: 08:14:10, elapsed time: 8 hours, 58 minutes, 37 seconds"
          ]
        }
      ],
      "source": [
        "# policy network\n",
        "def OurModel(input_shape, action_space):\n",
        "\n",
        "    input = tf.keras.layers.Input(input_shape)\n",
        "    s = input\n",
        "\n",
        "    c1 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3),padding='same',activation='relu', activity_regularizer='L1L2')(s)\n",
        "    c1 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3),padding='same',activation='relu')(c1)\n",
        "    do1 = tf.keras.layers.Dropout(0.15)(c1)\n",
        "\n",
        "    m1 = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(do1)\n",
        "\n",
        "    c2 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3),padding='same',activation='relu', activity_regularizer='L1L2')(m1)\n",
        "    c2 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3),padding='same',activation='relu')(c2)\n",
        "    do2 = tf.keras.layers.Dropout(0.15)(c2)\n",
        "\n",
        "    m2 = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(do2)\n",
        "\n",
        "    c3 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3),padding='same',activation='relu', activity_regularizer='L1L2')(m2)\n",
        "    c3 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3),padding='same',activation='relu')(c3)\n",
        "    c3 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3),padding='same',activation='relu')(c3)\n",
        "    do3 = tf.keras.layers.Dropout(0.15)(c3)\n",
        "\n",
        "    m3 = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(do3)\n",
        "\n",
        "    c4 = tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3),padding='same',activation='relu', activity_regularizer='L1L2')(m3)\n",
        "    c4 = tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3),padding='same',activation='relu')(c4)\n",
        "    c4 = tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3),padding='same',activation='relu')(c4)\n",
        "    do4 = tf.keras.layers.Dropout(0.15)(c4)\n",
        "\n",
        "    m4 = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(do4)\n",
        "\n",
        "    c5 = tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3),padding='same',activation='relu', activity_regularizer='L1L2')(m4)\n",
        "    c5 = tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3),padding='same',activation='relu')(c5)\n",
        "    c5 = tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3),padding='same',activation='relu')(c5)\n",
        "    do5 = tf.keras.layers.Dropout(0.15)(c5)\n",
        "\n",
        "    f1 = tf.keras.layers.Flatten()(do5)\n",
        "\n",
        "    d1 = tf.keras.layers.Dense(units=4096, activation='relu')(f1)\n",
        "    d2 = tf.keras.layers.Dense(units=1024, activation='relu')(d1)\n",
        "\n",
        "    d = tf.keras.layers.Dense(units=action_space, activation='linear')(d2)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=[input], outputs=[d])\n",
        "    \n",
        "    model.compile(loss=\"mse\", optimizer=Adam(learning_rate=0.001), metrics=[\"accuracy\"]) \n",
        "\n",
        "    # model.summary()\n",
        "    return model\n",
        "\n",
        "class DQNAgent:\n",
        "    def __init__(self):\n",
        "        self.env = DinoEnv()\n",
        "        self.state_size = self.env.observation_space.shape\n",
        "        #self.state_size = (120, 120, 4)\n",
        "        self.action_size = self.env.action_space.n\n",
        "        self.EPISODES = 1000\n",
        "        self.memory = deque(maxlen=2000)\n",
        "        \n",
        "        self.gamma = 0.95    # discount rate\n",
        "        self.epsilon = 1.0  # exploration rate\n",
        "        self.epsilon_min = 0.001\n",
        "        self.epsilon_decay = 0.999\n",
        "        self.batch_size = 128\n",
        "        self.train_start = 1000\n",
        "\n",
        "        # create main model\n",
        "        self.Target_model = OurModel(input_shape=self.state_size, action_space = self.action_size) \n",
        "        self.Train_model = OurModel(input_shape=self.state_size, action_space = self.action_size) \n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "        if len(self.memory) > self.train_start:\n",
        "            if self.epsilon > self.epsilon_min:\n",
        "                self.epsilon *= self.epsilon_decay\n",
        "    \n",
        "    # to do\n",
        "    # implement the epsilon-greedy policy\n",
        "    def act(self, state):\n",
        "        p = np.random.uniform() \n",
        "        if p < self.epsilon: \n",
        "          action = self.env.action_space.sample() \n",
        "        else: \n",
        "          q = self.Train_model.predict(state[np.newaxis,:]) \n",
        "          action = np.argmax(q) \n",
        "        return action \n",
        "\n",
        "    # to do\n",
        "    # implement the Q-learning\n",
        "    def replay(self): \n",
        "        if len(self.memory) < self.train_start:\n",
        "            return\n",
        "        # Randomly sample minibatch from the memory\n",
        "        minibatch = random.sample(self.memory, min(len(self.memory), self.batch_size))\n",
        "\n",
        "        #state = np.zeros((self.batch_size, self.state_size))\n",
        "        state = np.zeros((self.batch_size, 120, 120, 4))\n",
        "        #next_state = np.zeros((self.batch_size, self.state_size))\n",
        "        next_state = np.zeros((self.batch_size, 120, 120, 4))\n",
        "        action, reward, done, targets = [], [], [], [] \n",
        "\n",
        "        # assign data into state, next_state, action, reward and done from minibatch\n",
        "        for i in range(self.batch_size):\n",
        "            state[i] = minibatch[i][0] \n",
        "            next_state[i] = minibatch[i][3] \n",
        "            action.append(minibatch[i][1])\n",
        "            reward.append(minibatch[i][2])\n",
        "            done.append(minibatch[i][4]) \n",
        "\n",
        "        # compute value function of current state (call it target) and value function of next state (call it target_next)\n",
        "        for i in range(self.batch_size):\n",
        "            target = self.Train_model.predict(state[i][np.newaxis,:]) \n",
        "            target = target[0] \n",
        "            target_next = self.Target_model.predict(next_state[i][np.newaxis,:]) \n",
        "            target_next = target_next[0] \n",
        "\n",
        "            # correction on the Q value for the action used,\n",
        "            # if done[i] is true, then the target should be just the final reward\n",
        "            if not done[i]:\n",
        "                # else, use Bellman Equation\n",
        "                # Standard - DQN\n",
        "                # DQN chooses the max Q value among next actions\n",
        "                # selection and evaluation of action is on the target Q Network\n",
        "                # target = max_a' (r + gamma*Q_target_next(s', a'))\n",
        "\n",
        "                q_next = np.max(target_next) \n",
        "                new_q = reward[i] + self.gamma*q_next \n",
        "            else:\n",
        "                new_q = reward[i] \n",
        "\n",
        "            target[action[i]] = new_q\n",
        "            targets.append(target) \n",
        "\n",
        "        # Train the Neural Network with batches where target is the value function\n",
        "        targets = np.asarray(targets) \n",
        "        self.Train_model.fit(state, targets, batch_size=self.batch_size, verbose=0) \n",
        "\n",
        "    def load(self, name):\n",
        "        self.model = load_model(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        self.model.save(name)\n",
        "            \n",
        "    def training(self):\n",
        "        max = 0\n",
        "        total_r = [] \n",
        "        count = 25 \n",
        "        start = time.time() \n",
        "        self.env.Env_Start()\n",
        "\n",
        "        for e in range(self.EPISODES):\n",
        "            time.sleep(1.5)\n",
        "            state = self.env.reset()\n",
        "            done = False\n",
        "            i = 0\n",
        "            \n",
        "            while not done:\n",
        "                # if you have graphic support, you can render() to see the animation. \n",
        "                #self.env.render()\n",
        "                action = self.act(state)\n",
        "                next_state, reward, done, _ = self.env.step(action)\n",
        "                    \n",
        "                self.remember(state, action, reward, next_state, done)\n",
        "                state = next_state\n",
        "                \n",
        "                i += 1\n",
        "                if done:  \n",
        "                    if i > max:\n",
        "                      max = i \n",
        "                    dateTimeObj = datetime.now()\n",
        "                    timestampStr = dateTimeObj.strftime(\"%H:%M:%S\")\n",
        "\n",
        "                    end = time.time() \n",
        "                    elapse = np.abs(start-end) \n",
        "                    hour = elapse/3600\n",
        "                    minute = np.abs(elapse - (math.floor(hour) * 3600))/60 \n",
        "                    seconds = np.abs(minute - math.floor(minute)) * 60 \n",
        "                    print(f\"\\repisode: {e+1}/{self.EPISODES}, score: {i}, max score: {max}, e: {round(self.epsilon, 4)}, time: {timestampStr}, elapsed time: {math.floor(hour)} hours, {math.floor(minute)} minutes, {math.floor(seconds)} seconds\", end='', flush=True) \n",
        "                    #print(f\"episode: {e+1}/{self.EPISODES}, score: {i}, max score: {max}, e: {round(self.epsilon, 4)}, time: {timestampStr}, elapsed time: {math.floor(hour)} hours, {math.floor(minute)} minutes, {math.floor(seconds)} seconds\") \n",
        "                    total_r.append(i) \n",
        "\n",
        "                    self.replay() \n",
        "                    if e > count: \n",
        "                      count += e \n",
        "                      self.Target_model.set_weights(self.Train_model.get_weights()) \n",
        "\n",
        "        epi = np.linspace(0, self.EPISODES, self.EPISODES) \n",
        "        plt.plot(epi, total_r) \n",
        "        plt.xlabel('Episodes') \n",
        "        plt.ylabel('Total Reward') \n",
        "        plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\tagent = DQNAgent()\n",
        "\tagent.training()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DQN2"
      ],
      "metadata": {
        "id": "4XA-nAu_lfgu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DQN_():\n",
        "\tdef __init__(self, width=120, height=120):\n",
        "\t\tself.env_fnc = lambda: DinoEnv(width=120, height=120)\n",
        "\t\tself.env = DummyVecEnv([self.env_fnc])\n",
        "\t\t#self.env = DinoEnv(width=120, height=120, chrome_path=chrome_path)\n",
        "\t\tself.model = DQN(CnnPolicy_DQN, self.env, verbose=1, buffer_size=5000)\n",
        "\t\tself.save = 'chrome_dino_dqn'\n",
        "\n",
        "\tdef run(self):\n",
        "\t\t#self.env.Env_Start()\n",
        "\t\tprint('Begin training...')\n",
        "\t\tstart_train = time.time()\n",
        "\t\tself.model.learn(total_timesteps=2000000)\n",
        "\t\tself.model.save(self.save)\n",
        "\n",
        "\t\tend_train = time.time()\n",
        "\t\tself.model = DQN.load(self.save, env=self.env)\n",
        "\t\t\n",
        "\t\tprint('Begin Test Runs...')\n",
        "\t\ttotal_r = []\n",
        "\t\tmax = 0\n",
        "\t\tfor e in range(1000):\n",
        "\t\t\tdone = False\n",
        "\t\t\ttime.sleep(0.25)\n",
        "\t\t\tstate = self.env.reset()\n",
        "\t\t\tr = 0\n",
        "\t\t\twhile not done:\n",
        "\t\t\t\taction, _ = self.model.predict(state, deterministic=True)\n",
        "\t\t\t\tstate, reward, done, info = self.env.step(action)\n",
        "\t\t\t\tr +=1\n",
        "\t\t\t\tif done:\n",
        "\t\t\t\t\tif r > max:\n",
        "\t\t\t\t\t\tmax = r\n",
        "\t\t\t\t\tprint(f\"episode: {e+1}/{1000}, score: {r}, max score: {max}\") \n",
        "\t\t\t\t\ttotal_r.append(r)\n",
        "\t\t\t\t\tstate = self.env.reset()\n",
        "\n",
        "\t\telapse = np.abs(start-end) \n",
        "\t\thour = elapse/3600 \n",
        "\t\tminute = np.abs(elapse - (math.floor(hour) * 3600))/60 \n",
        "\t\tseconds = np.abs(minute - math.floor(minute)) * 60 \n",
        "\t\tprint(f'Total Training Time: {hour} hours, {minute} minutes, {seconds} seconds')\n",
        "\n",
        "\t\tepi = np.linspace(0, 1000, 1000) \n",
        "\t\tplt.plot(epi, total_r) \n",
        "\t\tplt.xlabel('Episodes') \n",
        "\t\tplt.ylabel('Total Reward') \n",
        "\t\tplt.show()"
      ],
      "metadata": {
        "id": "kIqIYVsvlg0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PPO"
      ],
      "metadata": {
        "id": "T9HkwRYMlugg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PPO_():\n",
        "\tdef __init__(self, width=120, height=120, cpu_process=1):\n",
        "\t\tself.episodes = 500\n",
        "\t\tself.env_fnc = lambda: DinoEnv(width=120, height=120)\n",
        "\t\tself.env = DummyVecEnv([self.env_fnc])\n",
        "\t\tself.model = PPO(CnnPolicy_PPO, self.env, verbose=1)\n",
        "\t\tself.save = 'chrome_dino_ppo'\n",
        "\t\tself.checkpoint = CheckpointCallback(save_freq=500000, save_path='./.checkpoints/', name_prefix=self.save)\n",
        "\n",
        "\tdef run(self):\n",
        "\t\t#self.env.Env_Start()\n",
        "\t\tprint('Begin training...')\n",
        "\t\tstart_train = time.time()\n",
        "\t\tself.model.learn(total_timesteps=500000, callback=[self.checkpoint])\n",
        "\t\tself.model.save(self.save)\n",
        "\n",
        "\t\tend_train = time.time()\n",
        "\t\tself.test_env = DummyVecEnv([self.env_fnc])\n",
        "\t\tself.model = PPO.load(self.save, env=self.test_env)\n",
        "\t\t\n",
        "\t\tprint('Begin Test Runs...')\n",
        "\t\ttotal_r = []\n",
        "\t\tmax = 0\n",
        "\t\tfor e in range(self.episodes):\n",
        "\t\t\tdone = False\n",
        "\t\t\tstate = self.test_env.reset()\n",
        "\t\t\tr = 0\n",
        "\t\t\ttime.sleep(1)\n",
        "\t\t\twhile not done:\n",
        "\t\t\t\taction, _ = self.model.predict(state, deterministic=True)\n",
        "\t\t\t\tstate, reward, done, info = self.test_env.step(action)\n",
        "\t\t\t\tr +=1\n",
        "\t\t\t\tif done:\n",
        "\t\t\t\t\tif r > max:\n",
        "\t\t\t\t\t\tmax = r\n",
        "\t\t\t\t\tprint(f\"episode: {e+1}/{self.episodes}, score: {r}, max score: {max}\") \n",
        "\t\t\t\t\tif r>1:\n",
        "\t\t\t\t\t\ttotal_r.append(r)\n",
        "\t\t\t\t\t#state = self.env.reset()\n",
        "\n",
        "\t\telapse = np.abs(start_train-end_train) \n",
        "\t\thour = elapse/3600 \n",
        "\t\tminute = np.abs(elapse - (math.floor(hour) * 3600))/60 \n",
        "\t\tseconds = np.abs(minute - math.floor(minute)) * 60 \n",
        "\t\tprint(f'Total Training Time: {hour} hours, {minute} minutes, {seconds} seconds')\t\n",
        "\n",
        "\t\tepi = np.linspace(0, len(total_r), len(total_r)) \n",
        "\t\tplt.plot(epi, total_r) \n",
        "\t\tplt.xlabel('Episodes') \n",
        "\t\tplt.ylabel('Total Reward') \n",
        "\t\tplt.show()"
      ],
      "metadata": {
        "id": "HAw2xi81lv-9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ppo = PPO_(cpu_process=2)\n",
        "ppo.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrSqWRR_l1RL",
        "outputId": "ea33c96e-bbd6-4d57-bd12-4e601077d255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Wrapping the env in a VecTransposeImage.\n",
            "Begin training...\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 18   |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 110  |\n",
            "|    total_timesteps | 2048 |\n",
            "-----------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 18          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 223         |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.032625884 |\n",
            "|    clip_fraction        | 0.294       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.07       |\n",
            "|    explained_variance   | 0.000574    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 106         |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | 0.0237      |\n",
            "|    value_loss           | 215         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 18          |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 337         |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.041186124 |\n",
            "|    clip_fraction        | 0.298       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.06       |\n",
            "|    explained_variance   | 0.823       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.42        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | 0.00202     |\n",
            "|    value_loss           | 89.9        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 18          |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 449         |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019757066 |\n",
            "|    clip_fraction        | 0.228       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.01       |\n",
            "|    explained_variance   | 0.839       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 10.4        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.00112    |\n",
            "|    value_loss           | 85.9        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 18          |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 562         |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020709481 |\n",
            "|    clip_fraction        | 0.318       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.953      |\n",
            "|    explained_variance   | 0.813       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.1         |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | 0.00958     |\n",
            "|    value_loss           | 64.6        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 6          |\n",
            "|    time_elapsed         | 674        |\n",
            "|    total_timesteps      | 12288      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.12941776 |\n",
            "|    clip_fraction        | 0.368      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.954     |\n",
            "|    explained_variance   | 0.802      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 3.86       |\n",
            "|    n_updates            | 50         |\n",
            "|    policy_gradient_loss | 0.0132     |\n",
            "|    value_loss           | 67         |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 18          |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 787         |\n",
            "|    total_timesteps      | 14336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.025033657 |\n",
            "|    clip_fraction        | 0.264       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.541      |\n",
            "|    explained_variance   | 0.8         |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.5         |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | 0.00948     |\n",
            "|    value_loss           | 44.2        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 8          |\n",
            "|    time_elapsed         | 899        |\n",
            "|    total_timesteps      | 16384      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.04272821 |\n",
            "|    clip_fraction        | 0.241      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.622     |\n",
            "|    explained_variance   | 0.754      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 3.69       |\n",
            "|    n_updates            | 70         |\n",
            "|    policy_gradient_loss | 0.00451    |\n",
            "|    value_loss           | 47.6       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 18        |\n",
            "|    iterations           | 9         |\n",
            "|    time_elapsed         | 1013      |\n",
            "|    total_timesteps      | 18432     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0547137 |\n",
            "|    clip_fraction        | 0.219     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.494    |\n",
            "|    explained_variance   | 0.821     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 4.48      |\n",
            "|    n_updates            | 80        |\n",
            "|    policy_gradient_loss | 0.00914   |\n",
            "|    value_loss           | 32.8      |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 18          |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 1124        |\n",
            "|    total_timesteps      | 20480       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021453112 |\n",
            "|    clip_fraction        | 0.233       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.499      |\n",
            "|    explained_variance   | 0.75        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.19        |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | 0.00825     |\n",
            "|    value_loss           | 40.8        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 18          |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 1237        |\n",
            "|    total_timesteps      | 22528       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.047379695 |\n",
            "|    clip_fraction        | 0.175       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.446      |\n",
            "|    explained_variance   | 0.737       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.19        |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | 0.00264     |\n",
            "|    value_loss           | 45.7        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 18          |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 1349        |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.051807534 |\n",
            "|    clip_fraction        | 0.185       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.502      |\n",
            "|    explained_variance   | 0.852       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.53        |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | 0.00903     |\n",
            "|    value_loss           | 32.5        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 18          |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 1462        |\n",
            "|    total_timesteps      | 26624       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.060105443 |\n",
            "|    clip_fraction        | 0.265       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.604      |\n",
            "|    explained_variance   | 0.726       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.59        |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.00522    |\n",
            "|    value_loss           | 35.8        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 18          |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 1566        |\n",
            "|    total_timesteps      | 28672       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.060441837 |\n",
            "|    clip_fraction        | 0.352       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.762      |\n",
            "|    explained_variance   | 0.835       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.11        |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | 0.0148      |\n",
            "|    value_loss           | 40.5        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 18          |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 1678        |\n",
            "|    total_timesteps      | 30720       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.047000468 |\n",
            "|    clip_fraction        | 0.317       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.669      |\n",
            "|    explained_variance   | 0.864       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.91        |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | 0.00687     |\n",
            "|    value_loss           | 27.1        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 16         |\n",
            "|    time_elapsed         | 1784       |\n",
            "|    total_timesteps      | 32768      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.13916324 |\n",
            "|    clip_fraction        | 0.357      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.726     |\n",
            "|    explained_variance   | 0.77       |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.882      |\n",
            "|    n_updates            | 150        |\n",
            "|    policy_gradient_loss | 0.0159     |\n",
            "|    value_loss           | 33.2       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 17         |\n",
            "|    time_elapsed         | 1886       |\n",
            "|    total_timesteps      | 34816      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.09935716 |\n",
            "|    clip_fraction        | 0.412      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.803     |\n",
            "|    explained_variance   | 0.633      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.21       |\n",
            "|    n_updates            | 160        |\n",
            "|    policy_gradient_loss | 0.0207     |\n",
            "|    value_loss           | 38.7       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 18          |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 1991        |\n",
            "|    total_timesteps      | 36864       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.115634374 |\n",
            "|    clip_fraction        | 0.445       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.79       |\n",
            "|    explained_variance   | 0.573       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.87        |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | 0.0272      |\n",
            "|    value_loss           | 48.9        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 19         |\n",
            "|    time_elapsed         | 2094       |\n",
            "|    total_timesteps      | 38912      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.06262089 |\n",
            "|    clip_fraction        | 0.356      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.755     |\n",
            "|    explained_variance   | 0.553      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 2.18       |\n",
            "|    n_updates            | 180        |\n",
            "|    policy_gradient_loss | 0.0185     |\n",
            "|    value_loss           | 96.9       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 20         |\n",
            "|    time_elapsed         | 2198       |\n",
            "|    total_timesteps      | 40960      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.08915967 |\n",
            "|    clip_fraction        | 0.392      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.664     |\n",
            "|    explained_variance   | 0.661      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.807      |\n",
            "|    n_updates            | 190        |\n",
            "|    policy_gradient_loss | 0.0252     |\n",
            "|    value_loss           | 52         |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 21         |\n",
            "|    time_elapsed         | 2307       |\n",
            "|    total_timesteps      | 43008      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.06784923 |\n",
            "|    clip_fraction        | 0.436      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.675     |\n",
            "|    explained_variance   | 0.621      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.23       |\n",
            "|    n_updates            | 200        |\n",
            "|    policy_gradient_loss | 0.0112     |\n",
            "|    value_loss           | 48.7       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 22         |\n",
            "|    time_elapsed         | 2414       |\n",
            "|    total_timesteps      | 45056      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.09235263 |\n",
            "|    clip_fraction        | 0.412      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.696     |\n",
            "|    explained_variance   | 0.659      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 2.41       |\n",
            "|    n_updates            | 210        |\n",
            "|    policy_gradient_loss | 0.0132     |\n",
            "|    value_loss           | 54.9       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 23         |\n",
            "|    time_elapsed         | 2523       |\n",
            "|    total_timesteps      | 47104      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.08432067 |\n",
            "|    clip_fraction        | 0.403      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.684     |\n",
            "|    explained_variance   | 0.509      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.54       |\n",
            "|    n_updates            | 220        |\n",
            "|    policy_gradient_loss | 0.0229     |\n",
            "|    value_loss           | 62.7       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 18        |\n",
            "|    iterations           | 24        |\n",
            "|    time_elapsed         | 2631      |\n",
            "|    total_timesteps      | 49152     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0969661 |\n",
            "|    clip_fraction        | 0.46      |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.708    |\n",
            "|    explained_variance   | 0.608     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1.61      |\n",
            "|    n_updates            | 230       |\n",
            "|    policy_gradient_loss | 0.0211    |\n",
            "|    value_loss           | 57.7      |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 25         |\n",
            "|    time_elapsed         | 2740       |\n",
            "|    total_timesteps      | 51200      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.27493715 |\n",
            "|    clip_fraction        | 0.412      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.64      |\n",
            "|    explained_variance   | 0.567      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.13       |\n",
            "|    n_updates            | 240        |\n",
            "|    policy_gradient_loss | 0.021      |\n",
            "|    value_loss           | 48.3       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 18          |\n",
            "|    iterations           | 26          |\n",
            "|    time_elapsed         | 2849        |\n",
            "|    total_timesteps      | 53248       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.055180877 |\n",
            "|    clip_fraction        | 0.366       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.615      |\n",
            "|    explained_variance   | 0.54        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.61        |\n",
            "|    n_updates            | 250         |\n",
            "|    policy_gradient_loss | 0.00598     |\n",
            "|    value_loss           | 64          |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 18          |\n",
            "|    iterations           | 27          |\n",
            "|    time_elapsed         | 2957        |\n",
            "|    total_timesteps      | 55296       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.119333275 |\n",
            "|    clip_fraction        | 0.387       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.595      |\n",
            "|    explained_variance   | 0.57        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.46        |\n",
            "|    n_updates            | 260         |\n",
            "|    policy_gradient_loss | 0.0274      |\n",
            "|    value_loss           | 64.1        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 28         |\n",
            "|    time_elapsed         | 3065       |\n",
            "|    total_timesteps      | 57344      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.07704142 |\n",
            "|    clip_fraction        | 0.377      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.609     |\n",
            "|    explained_variance   | 0.435      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.56       |\n",
            "|    n_updates            | 270        |\n",
            "|    policy_gradient_loss | 0.013      |\n",
            "|    value_loss           | 66.5       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 29         |\n",
            "|    time_elapsed         | 3174       |\n",
            "|    total_timesteps      | 59392      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.09711237 |\n",
            "|    clip_fraction        | 0.32       |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.549     |\n",
            "|    explained_variance   | 0.449      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 4.6        |\n",
            "|    n_updates            | 280        |\n",
            "|    policy_gradient_loss | 0.00169    |\n",
            "|    value_loss           | 79.3       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 30         |\n",
            "|    time_elapsed         | 3280       |\n",
            "|    total_timesteps      | 61440      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.10192415 |\n",
            "|    clip_fraction        | 0.328      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.543     |\n",
            "|    explained_variance   | 0.487      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 2.29       |\n",
            "|    n_updates            | 290        |\n",
            "|    policy_gradient_loss | -0.00906   |\n",
            "|    value_loss           | 65.2       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 18        |\n",
            "|    iterations           | 31        |\n",
            "|    time_elapsed         | 3391      |\n",
            "|    total_timesteps      | 63488     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.1489178 |\n",
            "|    clip_fraction        | 0.343     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.484    |\n",
            "|    explained_variance   | 0.58      |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 4.31      |\n",
            "|    n_updates            | 300       |\n",
            "|    policy_gradient_loss | -0.00373  |\n",
            "|    value_loss           | 61.5      |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 32         |\n",
            "|    time_elapsed         | 3498       |\n",
            "|    total_timesteps      | 65536      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.25671652 |\n",
            "|    clip_fraction        | 0.306      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.308     |\n",
            "|    explained_variance   | 0.712      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.99       |\n",
            "|    n_updates            | 310        |\n",
            "|    policy_gradient_loss | 0.0176     |\n",
            "|    value_loss           | 57         |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 18          |\n",
            "|    iterations           | 33          |\n",
            "|    time_elapsed         | 3605        |\n",
            "|    total_timesteps      | 67584       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.079122886 |\n",
            "|    clip_fraction        | 0.268       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.411      |\n",
            "|    explained_variance   | 0.635       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.02        |\n",
            "|    n_updates            | 320         |\n",
            "|    policy_gradient_loss | -0.00366    |\n",
            "|    value_loss           | 43.6        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 34         |\n",
            "|    time_elapsed         | 3714       |\n",
            "|    total_timesteps      | 69632      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.13279404 |\n",
            "|    clip_fraction        | 0.313      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.443     |\n",
            "|    explained_variance   | 0.636      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.57       |\n",
            "|    n_updates            | 330        |\n",
            "|    policy_gradient_loss | 0.012      |\n",
            "|    value_loss           | 56.9       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 18        |\n",
            "|    iterations           | 35        |\n",
            "|    time_elapsed         | 3822      |\n",
            "|    total_timesteps      | 71680     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.1362941 |\n",
            "|    clip_fraction        | 0.316     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.359    |\n",
            "|    explained_variance   | 0.499     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1.08      |\n",
            "|    n_updates            | 340       |\n",
            "|    policy_gradient_loss | 0.0369    |\n",
            "|    value_loss           | 68.5      |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 36         |\n",
            "|    time_elapsed         | 3928       |\n",
            "|    total_timesteps      | 73728      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.19175726 |\n",
            "|    clip_fraction        | 0.232      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.366     |\n",
            "|    explained_variance   | 0.542      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 3.65       |\n",
            "|    n_updates            | 350        |\n",
            "|    policy_gradient_loss | -0.00863   |\n",
            "|    value_loss           | 63.6       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 37         |\n",
            "|    time_elapsed         | 4037       |\n",
            "|    total_timesteps      | 75776      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.11736709 |\n",
            "|    clip_fraction        | 0.329      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.443     |\n",
            "|    explained_variance   | 0.536      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.97       |\n",
            "|    n_updates            | 360        |\n",
            "|    policy_gradient_loss | 0.0184     |\n",
            "|    value_loss           | 53.9       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 38         |\n",
            "|    time_elapsed         | 4143       |\n",
            "|    total_timesteps      | 77824      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.07849005 |\n",
            "|    clip_fraction        | 0.357      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.566     |\n",
            "|    explained_variance   | 0.594      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.28       |\n",
            "|    n_updates            | 370        |\n",
            "|    policy_gradient_loss | 0.0147     |\n",
            "|    value_loss           | 38.2       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 39         |\n",
            "|    time_elapsed         | 4250       |\n",
            "|    total_timesteps      | 79872      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.09760035 |\n",
            "|    clip_fraction        | 0.401      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.564     |\n",
            "|    explained_variance   | 0.599      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.18       |\n",
            "|    n_updates            | 380        |\n",
            "|    policy_gradient_loss | 0.02       |\n",
            "|    value_loss           | 53.2       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 18          |\n",
            "|    iterations           | 40          |\n",
            "|    time_elapsed         | 4356        |\n",
            "|    total_timesteps      | 81920       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.077147804 |\n",
            "|    clip_fraction        | 0.343       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.556      |\n",
            "|    explained_variance   | 0.56        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.82        |\n",
            "|    n_updates            | 390         |\n",
            "|    policy_gradient_loss | 0.00104     |\n",
            "|    value_loss           | 42.7        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 41         |\n",
            "|    time_elapsed         | 4463       |\n",
            "|    total_timesteps      | 83968      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.11052781 |\n",
            "|    clip_fraction        | 0.408      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.555     |\n",
            "|    explained_variance   | 0.466      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1          |\n",
            "|    n_updates            | 400        |\n",
            "|    policy_gradient_loss | 0.03       |\n",
            "|    value_loss           | 88.6       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 42         |\n",
            "|    time_elapsed         | 4569       |\n",
            "|    total_timesteps      | 86016      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.14601922 |\n",
            "|    clip_fraction        | 0.345      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.473     |\n",
            "|    explained_variance   | 0.413      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 19.9       |\n",
            "|    n_updates            | 410        |\n",
            "|    policy_gradient_loss | 0.0125     |\n",
            "|    value_loss           | 119        |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 43         |\n",
            "|    time_elapsed         | 4676       |\n",
            "|    total_timesteps      | 88064      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.10905969 |\n",
            "|    clip_fraction        | 0.326      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.456     |\n",
            "|    explained_variance   | 0.337      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.28       |\n",
            "|    n_updates            | 420        |\n",
            "|    policy_gradient_loss | 0.0144     |\n",
            "|    value_loss           | 79.5       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 44         |\n",
            "|    time_elapsed         | 4783       |\n",
            "|    total_timesteps      | 90112      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.14595234 |\n",
            "|    clip_fraction        | 0.29       |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.384     |\n",
            "|    explained_variance   | 0.535      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 2.36       |\n",
            "|    n_updates            | 430        |\n",
            "|    policy_gradient_loss | 0.00964    |\n",
            "|    value_loss           | 44.8       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 45         |\n",
            "|    time_elapsed         | 4890       |\n",
            "|    total_timesteps      | 92160      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.17339544 |\n",
            "|    clip_fraction        | 0.375      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.432     |\n",
            "|    explained_variance   | 0.505      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.7        |\n",
            "|    n_updates            | 440        |\n",
            "|    policy_gradient_loss | 0.0281     |\n",
            "|    value_loss           | 74.4       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 18          |\n",
            "|    iterations           | 46          |\n",
            "|    time_elapsed         | 4997        |\n",
            "|    total_timesteps      | 94208       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.093787484 |\n",
            "|    clip_fraction        | 0.287       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.361      |\n",
            "|    explained_variance   | 0.599       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.41        |\n",
            "|    n_updates            | 450         |\n",
            "|    policy_gradient_loss | 0.0132      |\n",
            "|    value_loss           | 66.1        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 18          |\n",
            "|    iterations           | 47          |\n",
            "|    time_elapsed         | 5106        |\n",
            "|    total_timesteps      | 96256       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.124024704 |\n",
            "|    clip_fraction        | 0.359       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.419      |\n",
            "|    explained_variance   | 0.601       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.68        |\n",
            "|    n_updates            | 460         |\n",
            "|    policy_gradient_loss | 0.0232      |\n",
            "|    value_loss           | 57.6        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 48         |\n",
            "|    time_elapsed         | 5214       |\n",
            "|    total_timesteps      | 98304      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.09836337 |\n",
            "|    clip_fraction        | 0.281      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.336     |\n",
            "|    explained_variance   | 0.596      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 5.33       |\n",
            "|    n_updates            | 470        |\n",
            "|    policy_gradient_loss | 0.0152     |\n",
            "|    value_loss           | 110        |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 49         |\n",
            "|    time_elapsed         | 5313       |\n",
            "|    total_timesteps      | 100352     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.13978739 |\n",
            "|    clip_fraction        | 0.268      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.278     |\n",
            "|    explained_variance   | 0.726      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.84       |\n",
            "|    n_updates            | 480        |\n",
            "|    policy_gradient_loss | 0.0381     |\n",
            "|    value_loss           | 97.2       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 18        |\n",
            "|    iterations           | 50        |\n",
            "|    time_elapsed         | 5414      |\n",
            "|    total_timesteps      | 102400    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.1871872 |\n",
            "|    clip_fraction        | 0.314     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.356    |\n",
            "|    explained_variance   | 0.485     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.976     |\n",
            "|    n_updates            | 490       |\n",
            "|    policy_gradient_loss | 0.0367    |\n",
            "|    value_loss           | 88        |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 18          |\n",
            "|    iterations           | 51          |\n",
            "|    time_elapsed         | 5516        |\n",
            "|    total_timesteps      | 104448      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.083812885 |\n",
            "|    clip_fraction        | 0.247       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.338      |\n",
            "|    explained_variance   | 0.293       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.53        |\n",
            "|    n_updates            | 500         |\n",
            "|    policy_gradient_loss | 0.00889     |\n",
            "|    value_loss           | 112         |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 52         |\n",
            "|    time_elapsed         | 5618       |\n",
            "|    total_timesteps      | 106496     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.07722058 |\n",
            "|    clip_fraction        | 0.253      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.328     |\n",
            "|    explained_variance   | 0.489      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 2.28       |\n",
            "|    n_updates            | 510        |\n",
            "|    policy_gradient_loss | 0.0156     |\n",
            "|    value_loss           | 96.2       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 18          |\n",
            "|    iterations           | 53          |\n",
            "|    time_elapsed         | 5726        |\n",
            "|    total_timesteps      | 108544      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.099144906 |\n",
            "|    clip_fraction        | 0.256       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.347      |\n",
            "|    explained_variance   | 0.414       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.69        |\n",
            "|    n_updates            | 520         |\n",
            "|    policy_gradient_loss | 0.00417     |\n",
            "|    value_loss           | 61.9        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 18          |\n",
            "|    iterations           | 54          |\n",
            "|    time_elapsed         | 5832        |\n",
            "|    total_timesteps      | 110592      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.091285825 |\n",
            "|    clip_fraction        | 0.205       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.241      |\n",
            "|    explained_variance   | 0.584       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.775       |\n",
            "|    n_updates            | 530         |\n",
            "|    policy_gradient_loss | 0.0126      |\n",
            "|    value_loss           | 58.8        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 55         |\n",
            "|    time_elapsed         | 5940       |\n",
            "|    total_timesteps      | 112640     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.08463542 |\n",
            "|    clip_fraction        | 0.18       |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.23      |\n",
            "|    explained_variance   | 0.565      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.67       |\n",
            "|    n_updates            | 540        |\n",
            "|    policy_gradient_loss | -0.00302   |\n",
            "|    value_loss           | 44.3       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 56         |\n",
            "|    time_elapsed         | 6046       |\n",
            "|    total_timesteps      | 114688     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.19347864 |\n",
            "|    clip_fraction        | 0.203      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.263     |\n",
            "|    explained_variance   | 0.54       |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.39       |\n",
            "|    n_updates            | 550        |\n",
            "|    policy_gradient_loss | -2.01e-05  |\n",
            "|    value_loss           | 50.6       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 57         |\n",
            "|    time_elapsed         | 6152       |\n",
            "|    total_timesteps      | 116736     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.23990709 |\n",
            "|    clip_fraction        | 0.252      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.25      |\n",
            "|    explained_variance   | 0.501      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.56       |\n",
            "|    n_updates            | 560        |\n",
            "|    policy_gradient_loss | 0.0239     |\n",
            "|    value_loss           | 59.8       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 58         |\n",
            "|    time_elapsed         | 6259       |\n",
            "|    total_timesteps      | 118784     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.56364334 |\n",
            "|    clip_fraction        | 0.282      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.227     |\n",
            "|    explained_variance   | 0.465      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.02       |\n",
            "|    n_updates            | 570        |\n",
            "|    policy_gradient_loss | 0.0329     |\n",
            "|    value_loss           | 42.2       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 59         |\n",
            "|    time_elapsed         | 6367       |\n",
            "|    total_timesteps      | 120832     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.50552607 |\n",
            "|    clip_fraction        | 0.218      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.262     |\n",
            "|    explained_variance   | 0.558      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.2        |\n",
            "|    n_updates            | 580        |\n",
            "|    policy_gradient_loss | -0.0231    |\n",
            "|    value_loss           | 56.3       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 18        |\n",
            "|    iterations           | 60        |\n",
            "|    time_elapsed         | 6474      |\n",
            "|    total_timesteps      | 122880    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.1826192 |\n",
            "|    clip_fraction        | 0.329     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.346    |\n",
            "|    explained_variance   | 0.734     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.86      |\n",
            "|    n_updates            | 590       |\n",
            "|    policy_gradient_loss | 0.0334    |\n",
            "|    value_loss           | 39.8      |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 61         |\n",
            "|    time_elapsed         | 6582       |\n",
            "|    total_timesteps      | 124928     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.22481617 |\n",
            "|    clip_fraction        | 0.348      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.405     |\n",
            "|    explained_variance   | 0.621      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.35       |\n",
            "|    n_updates            | 600        |\n",
            "|    policy_gradient_loss | 0.0129     |\n",
            "|    value_loss           | 52.4       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 62         |\n",
            "|    time_elapsed         | 6689       |\n",
            "|    total_timesteps      | 126976     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.08517169 |\n",
            "|    clip_fraction        | 0.275      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.348     |\n",
            "|    explained_variance   | 0.469      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.64       |\n",
            "|    n_updates            | 610        |\n",
            "|    policy_gradient_loss | 0.00356    |\n",
            "|    value_loss           | 65.7       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 63         |\n",
            "|    time_elapsed         | 6797       |\n",
            "|    total_timesteps      | 129024     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.10002561 |\n",
            "|    clip_fraction        | 0.209      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.274     |\n",
            "|    explained_variance   | 0.683      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.57       |\n",
            "|    n_updates            | 620        |\n",
            "|    policy_gradient_loss | 0.00552    |\n",
            "|    value_loss           | 47.9       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 64         |\n",
            "|    time_elapsed         | 6904       |\n",
            "|    total_timesteps      | 131072     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.07612096 |\n",
            "|    clip_fraction        | 0.221      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.291     |\n",
            "|    explained_variance   | 0.589      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.28       |\n",
            "|    n_updates            | 630        |\n",
            "|    policy_gradient_loss | 0.0105     |\n",
            "|    value_loss           | 75.9       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 65         |\n",
            "|    time_elapsed         | 7011       |\n",
            "|    total_timesteps      | 133120     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.09358843 |\n",
            "|    clip_fraction        | 0.295      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.39      |\n",
            "|    explained_variance   | 0.462      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.664      |\n",
            "|    n_updates            | 640        |\n",
            "|    policy_gradient_loss | -0.00176   |\n",
            "|    value_loss           | 50.9       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 66         |\n",
            "|    time_elapsed         | 7117       |\n",
            "|    total_timesteps      | 135168     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.12341134 |\n",
            "|    clip_fraction        | 0.299      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.383     |\n",
            "|    explained_variance   | 0.528      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.45       |\n",
            "|    n_updates            | 650        |\n",
            "|    policy_gradient_loss | 0.0102     |\n",
            "|    value_loss           | 48.7       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 67         |\n",
            "|    time_elapsed         | 7224       |\n",
            "|    total_timesteps      | 137216     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.13155526 |\n",
            "|    clip_fraction        | 0.282      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.394     |\n",
            "|    explained_variance   | 0.444      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.611      |\n",
            "|    n_updates            | 660        |\n",
            "|    policy_gradient_loss | 0.0101     |\n",
            "|    value_loss           | 55         |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 18         |\n",
            "|    iterations           | 68         |\n",
            "|    time_elapsed         | 7332       |\n",
            "|    total_timesteps      | 139264     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.16625237 |\n",
            "|    clip_fraction        | 0.361      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.414     |\n",
            "|    explained_variance   | 0.516      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 2.86       |\n",
            "|    n_updates            | 670        |\n",
            "|    policy_gradient_loss | 0.00939    |\n",
            "|    value_loss           | 58.6       |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                   |          |\n",
            "|    fps                  | 18       |\n",
            "|    iterations           | 69       |\n",
            "|    time_elapsed         | 7440     |\n",
            "|    total_timesteps      | 141312   |\n",
            "| train/                  |          |\n",
            "|    approx_kl            | 0.136688 |\n",
            "|    clip_fraction        | 0.35     |\n",
            "|    clip_range           | 0.2      |\n",
            "|    entropy_loss         | -0.431   |\n",
            "|    explained_variance   | 0.203    |\n",
            "|    learning_rate        | 0.0003   |\n",
            "|    loss                 | 0.94     |\n",
            "|    n_updates            | 680      |\n",
            "|    policy_gradient_loss | 0.0206   |\n",
            "|    value_loss           | 66.4     |\n",
            "--------------------------------------\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "iaAALNxTlqTN",
        "bSNO0Sd7lbOY",
        "4XA-nAu_lfgu"
      ],
      "name": "Dino_Game_RL_DQN.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}